diff --git a/lib/carbon/cache.py b/carbon/lib/carbon/cache.py
index e98daa1..3129ea0 100644
--- a/lib/carbon/cache.py
+++ b/lib/carbon/cache.py
@@ -19,13 +19,14 @@ from carbon import log
 class MetricCache(dict):
   def __init__(self):
     self.size = 0
+    self.aggregateTypes = dict()
 
 
   def __setitem__(self, key, value):
     raise TypeError("Use store() method instead!")
 
 
-  def store(self, metric, datapoint):
+  def store(self, metric, datapoint, aggregate=None):
     if self.isFull():
       return
 
@@ -40,6 +41,9 @@ class MetricCache(dict):
     dict.__setitem__(self, metric, datapoints)
     self.size += 1
 
+    if aggregate:
+        self.aggregateTypes[metric] = aggregate
+
 
   def isFull(self):
     return self.size >= settings.MAX_CACHE_SIZE
@@ -54,6 +58,9 @@ class MetricCache(dict):
   def counts(self):
     return [ (metric, len(datapoints)) for (metric, datapoints) in self.items() ]
 
+
+  def aggregationFor(self, metric):
+      return self.aggregateTypes.get(metric)
   
 
 MetricCache = MetricCache()
diff --git a/lib/carbon/listeners.py b/carbon/lib/carbon/listeners.py
index 4bc8ce2..1c82a14 100644
--- a/lib/carbon/listeners.py
+++ b/lib/carbon/listeners.py
@@ -32,14 +32,16 @@ class MetricLineReceiver(LoggingMixin, LineOnlyReceiver):
 
   def lineReceived(self, line):
     try:
-      metric, value, timestamp = line.strip().split()
+      data = line.strip().split()
+      metric, value, timestamp = data[0:3]
+      aggregate = len(data) > 3 and data[3] or None
       datapoint = ( float(timestamp), float(value) )
     except:
       log.listener('invalid line received from client %s, ignoring' % self.peerAddr)
       return
 
     increment('metricsReceived')
-    metricReceived(metric, datapoint)
+    metricReceived(metric, datapoint, aggregate=aggregate)
 
 
 class MetricPickleReceiver(LoggingMixin, Int32StringReceiver):
diff --git a/lib/carbon/storage.py b/carbon/lib/carbon/storage.py
index 9fe9c8a..53a5e4c 100644
--- a/lib/carbon/storage.py
+++ b/lib/carbon/storage.py
@@ -79,31 +79,34 @@ class Schema:
 
 
 class DefaultSchema(Schema):
-  def __init__(self, name, archives):
+  def __init__(self, name, archives, aggregate):
     self.name = name
     self.archives = archives
+    self.aggregate = aggregate
 
   def test(self, metric):
     return True
 
 
 class PatternSchema(Schema):
-  def __init__(self, name, pattern, archives):
+  def __init__(self, name, pattern, archives, aggregate):
     self.name = name
     self.pattern = pattern
     self.regex = re.compile(pattern)
     self.archives = archives
+    self.aggregate = aggregate
 
   def test(self, metric):
     return self.regex.search(metric)
 
 
 class ListSchema(Schema):
-  def __init__(self, name, listName, archives):
+  def __init__(self, name, listName, archives, aggregate):
     self.name = name
     self.listName = listName
     self.archives = archives
     self.path = join(WHITELISTS_DIR, listName)
+    self.aggregate = aggregate
 
     if exists(self.path):
       self.mtime = os.stat(self.path).st_mtime
@@ -156,18 +159,19 @@ def loadStorageSchemas():
     matchAll = options.get('match-all')
     pattern = options.get('pattern')
     listName = options.get('list')
+    aggregate = options.get('aggregate')
 
     retentions = options['retentions'].split(',')
     archives = [ Archive.fromString(s) for s in retentions ]
 
     if matchAll:
-      mySchema = DefaultSchema(section, archives)
+      mySchema = DefaultSchema(section, archives, aggregate)
 
     elif pattern:
-      mySchema = PatternSchema(section, pattern, archives)
+      mySchema = PatternSchema(section, pattern, archives, aggregate)
 
     elif listName:
-      mySchema = ListSchema(section, listName, archives)
+      mySchema = ListSchema(section, listName, archives, aggregate)
 
     else:
       raise ValueError('schema "%s" has no pattern or list parameter configured' % section)
@@ -179,4 +183,4 @@ def loadStorageSchemas():
 
 
 defaultArchive = Archive(60, 60 * 24 * 7) #default retention for unclassified data (7 days of minutely data)
-defaultSchema = DefaultSchema('default', [defaultArchive])
+defaultSchema = DefaultSchema('default', [defaultArchive], 'average')
diff --git a/lib/carbon/writer.py b/carbon/lib/carbon/writer.py
index 4d2d59f..29a1794 100644
--- a/lib/carbon/writer.py
+++ b/lib/carbon/writer.py
@@ -91,11 +91,13 @@ def writeCachedDataPoints():
 
       if not dbFileExists:
         archiveConfig = None
+        aggregationMethod = None
 
         for schema in schemas:
           if schema.matches(metric):
             log.creates('new metric %s matched schema %s' % (metric, schema.name))
             archiveConfig = [archive.getTuple() for archive in schema.archives]
+            aggregationMethod = schema.aggregate
             break
 
         if not archiveConfig:
@@ -104,8 +106,11 @@ def writeCachedDataPoints():
         dbDir = dirname(dbFilePath)
         os.system("mkdir -p -m 755 '%s'" % dbDir)
 
-        log.creates("creating database file %s" % dbFilePath)
-        whisper.create(dbFilePath, archiveConfig)
+        if MetricCache.aggregationFor(metric):
+            aggregationMethod = MetricCache.aggregationFor(metric)
+
+        log.creates("creating database file %s (aggregationMethod: %s)" % (dbFilePath, aggregationMethod))
+        whisper.create(dbFilePath, archiveConfig, aggregationMethod=aggregationMethod)
         os.chmod(dbFilePath, 0755)
         increment('creates')
 
diff --git a/lib/carbon/listeners.py b/lib/carbon/listeners.py
index eee87cb..08e03dc 100644
--- a/lib/carbon/listeners.py
+++ b/lib/carbon/listeners.py
@@ -48,11 +48,13 @@ class MetricDatagramReceiver(LoggingMixin, DatagramProtocol):
   def datagramReceived(self, data, (host, port)):
     for line in data.splitlines():
       try:
-        metric, value, timestamp = line.strip().split()
+        data = line.strip().split()
+        metric, value, timestamp = data[0:3]
+        aggregate = len(data) > 3 and data[3] or None
         datapoint = ( float(timestamp), float(value) )
 
         increment('metricsReceived')
-        metricReceived(metric, datapoint)
+        metricReceived(metric, datapoint, aggregate=aggregate)
       except:
         log.listener('invalid line received from client %s, ignoring' % host)
 
