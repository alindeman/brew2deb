diff --git a/bin/whisper-create.py b/whisper/bin/whisper-create.py
index 551aac4..0e40a68 100755
--- a/bin/whisper-create.py
+++ b/bin/whisper-create.py
@@ -6,6 +6,7 @@ from optparse import OptionParser
 
 option_parser = OptionParser(usage='''%prog path secondsPerPoint:pointsToStore [secondsPerPoint:pointsToStore]* ''')
 option_parser.add_option('--xFilesFactor', default=0.5, type='float')
+option_parser.add_option('--aggregationMethod', default='average', type='string', help="Method to use when aggregating values into lower precisions (average, sum, last, min, max)")
 option_parser.add_option('--overwrite', default=False, action='store_true')
 
 (options, args) = option_parser.parse_args()
@@ -21,7 +22,7 @@ if options.overwrite and os.path.exists(path):
   print 'Overwriting existing file: %s' % path
   os.unlink(path)
 
-whisper.create(path, archives, xFilesFactor=options.xFilesFactor)
+whisper.create(path, archives, xFilesFactor=options.xFilesFactor, aggregationMethod=options.aggregationMethod)
 
 size = os.stat(path).st_size
 print 'Created: %s (%d bytes)' % (path,size)
diff --git a/bin/whisper-resize.py b/whisper/bin/whisper-resize.py
index 53e9a87..b3af1d1 100755
--- a/bin/whisper-resize.py
+++ b/bin/whisper-resize.py
@@ -56,6 +56,7 @@ precision and retention specify lengths of time, for example:
 12h:2y       12 hours per datapoint, 2 years of retention
 ''')
 option_parser.add_option('--xFilesFactor', default=None, type='float', help="Change the xFilesFactor")
+option_parser.add_option('--aggregationMethod', default=None, type='string', help="Change the aggregation method used (average, sum, last, min, max)")
 option_parser.add_option('--force', default=False, action='store_true', help="Perform a destructive change")
 option_parser.add_option('--newfile', default=None, action='store', help="Create a new database file without removing the existing one")
 option_parser.add_option('--nobackup', action='store_true', help='Delete the .bak file after successful execution')
@@ -78,6 +79,11 @@ if options.xFilesFactor is None:
 else:
   xff = options.xFilesFactor
 
+if options.aggregationMethod is None:
+  aggregationMethod = info['aggregationMethod']
+else:
+  aggregationMethod = options.aggregationMethod
+
 print 'Retrieving all data from the archives'
 for archive in old_archives:
   fromTime = now - archive['retention'] + archive['secondsPerPoint']
@@ -95,7 +101,7 @@ else:
   newfile = options.newfile
 
 print 'Creating new whisper database: %s' % newfile
-whisper.create(newfile, new_archives, xFilesFactor=xff)
+whisper.create(newfile, new_archives, xFilesFactor=xff, aggregationMethod=aggregationMethod)
 size = os.stat(newfile).st_size
 print 'Created: %s (%d bytes)' % (newfile,size)
 
diff --git a/whisper.py b/whisper/whisper.py
index 8d3d336..fb8ba2b 100644
--- a/whisper.py
+++ b/whisper.py
@@ -43,8 +41,6 @@ longFormat = "!L"
 longSize = struct.calcsize(longFormat)
 floatFormat = "!f"
 floatSize = struct.calcsize(floatFormat)
-timestampFormat = "!L"
-timestampSize = struct.calcsize(timestampFormat)
 valueFormat = "!d"
 valueSize = struct.calcsize(valueFormat)
 pointFormat = "!Ld"
@@ -54,6 +50,15 @@ metadataSize = struct.calcsize(metadataFormat)
 archiveInfoFormat = "!3L"
 archiveInfoSize = struct.calcsize(archiveInfoFormat)
 
+aggregationTypeToMethod = dict({
+  1: 'average',
+  2: 'sum',
+  3: 'last',
+  4: 'max',
+  5: 'min'
+})
+aggregationMethodToType = dict([[v,k] for k,v in aggregationTypeToMethod.items()])
+
 debug = startBlock = endBlock = lambda *a,**k: None
 
 
@@ -65,6 +70,10 @@ class InvalidConfiguration(WhisperException):
     """Invalid configuration."""
 
 
+class InvalidAggregationMethod(WhisperException):
+    """Invalid aggregation method."""
+
+
 class InvalidTimeInterval(WhisperException):
     """Invalid time interval."""
 
@@ -122,7 +131,7 @@ def __readHeader(fh):
   packedMetadata = fh.read(metadataSize)
 
   try:
-    (lastUpdate,maxRetention,xff,archiveCount) = struct.unpack(metadataFormat,packedMetadata)
+    (aggregationType,maxRetention,xff,archiveCount) = struct.unpack(metadataFormat,packedMetadata)
   except:
     raise CorruptWhisperFile("Unable to read header", fh.name)
 
@@ -146,7 +155,7 @@ def __readHeader(fh):
 
   fh.seek(originalOffset)
   info = {
-    #'lastUpdate' : lastUpdate, # Deprecated
+    'aggregationMethod' : aggregationTypeToMethod.get(aggregationType, 'average'),
     'maxRetention' : maxRetention,
     'xFilesFactor' : xff,
     'archives' : archives,
@@ -159,20 +168,15 @@ def __readHeader(fh):
 
 def __changeLastUpdate(fh):
   return #XXX Make this a NOP, use os.stat(filename).st_mtime instead
-  originalOffset = fh.tell()
-  fh.seek(0) #Based on assumption that first field is lastUpdate
-  now = int( time.time() )
-  packedTime = struct.pack(timestampFormat,now)
-  fh.write(packedTime)
-  fh.seek(originalOffset)
 
 
-def create(path,archiveList,xFilesFactor=0.5):
-  """create(path,archiveList,xFilesFactor=0.5)
+def create(path,archiveList,xFilesFactor=0.5,aggregationMethod='average'):
+  """create(path,archiveList,xFilesFactor=0.5,aggregationMethod='average')
 
 path is a string
 archiveList is a list of archives, each of which is of the form (secondsPerPoint,numberOfPoints)
 xFilesFactor specifies the fraction of data points in a propagation interval that must have known values for a propagation to occur
+aggregationMethod specifies the method to use when propogating data (average, sum, last, min, max)
 """
   #Validate archive configurations...
   if not archiveList:
@@ -210,12 +214,12 @@ xFilesFactor specifies the fraction of data points in a propagation interval tha
   if LOCK:
     fcntl.flock( fh.fileno(), fcntl.LOCK_EX )
 
-  lastUpdate = struct.pack( timestampFormat, int(time.time()) )
+  aggregationType = struct.pack( longFormat, aggregationMethodToType[aggregationMethod] )
   oldest = sorted([secondsPerPoint * points for secondsPerPoint,points in archiveList])[-1]
   maxRetention = struct.pack( longFormat, oldest )
   xFilesFactor = struct.pack( floatFormat, float(xFilesFactor) )
   archiveCount = struct.pack(longFormat, len(archiveList))
-  packedMetadata = lastUpdate + maxRetention + xFilesFactor + archiveCount
+  packedMetadata = aggregationType + maxRetention + xFilesFactor + archiveCount
   fh.write(packedMetadata)
   headerSize = metadataSize + (archiveInfoSize * len(archiveList))
   archiveOffsetPointer = headerSize
@@ -234,8 +238,22 @@ xFilesFactor specifies the fraction of data points in a propagation interval tha
 
   fh.close()
 
+def __aggregate(aggregationMethod, knownValues):
+  if aggregationMethod == 'average':
+    return float(sum(knownValues)) / float(len(knownValues))
+  elif aggregationMethod == 'sum':
+    return float(sum(knownValues))
+  elif aggregationMethod == 'last':
+    return knownValues[len(knownValues)-1]
+  elif aggregationMethod == 'max':
+    return max(knownValues)
+  elif aggregationMethod == 'min':
+    return min(knownValues)
+  else:
+    raise InvalidAggregationMethod("Unrecognized aggregation method")
+
 
-def __propagate(fh,timestamp,xff,higher,lower):
+def __propagate(fh,timestamp,aggregationMethod,xff,higher,lower):
   lowerIntervalStart = timestamp - (timestamp % lower['secondsPerPoint'])
   lowerIntervalEnd = lowerIntervalStart + lower['secondsPerPoint']
 
@@ -290,7 +308,7 @@ def __propagate(fh,timestamp,xff,higher,lower):
 
   knownPercent = float(len(knownValues)) / float(len(neighborValues))
   if knownPercent >= xff: #we have enough data to propagate a value!
-    aggregateValue = float(sum(knownValues)) / float(len(knownValues)) #TODO another CF besides average?
+    aggregateValue = __aggregate(aggregationMethod, knownValues)
     myPackedPoint = struct.pack(pointFormat,lowerIntervalStart,aggregateValue)
     fh.seek(lower['offset'])
     packedPoint = fh.read(pointSize)
@@ -367,7 +385,7 @@ def file_update(fh, value, timestamp):
   #Now we propagate the update to lower-precision archives
   higher = archive
   for lower in lowerArchives:
-    if not __propagate(fh, myInterval, header['xFilesFactor'], higher, lower):
+    if not __propagate(fh, myInterval, header['aggregationMethod'], header['xFilesFactor'], higher, lower):
       break
     higher = lower
 
@@ -493,7 +511,7 @@ def __archive_update_many(fh,header,archive,points):
     uniqueLowerIntervals = set(lowerIntervals)
     propagateFurther = False
     for interval in uniqueLowerIntervals:
-      if __propagate(fh,interval,header['xFilesFactor'],higher,lower):
+      if __propagate(fh,interval,header['aggregationMethod'],header['xFilesFactor'],higher,lower):
         propagateFurther = True
 
     if not propagateFurther:

